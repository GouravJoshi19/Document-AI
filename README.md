# Document Q&A App

üíª **Tech Stack**
- **Streamlit**: Frontend web framework for the UI.
- **Langchain**: Manages AI model chains for handling conversation workflows.
- **Cohere API**: For language model processing.
- **Pinecone**: Vector database for similarity search.
- **Docker**: Containerizes the application for easy deployment.

üîß **System Requirements**
- Python 3.7 or higher
- Docker (optional, for containerized setup)

### API keys for:
- **Cohere**: For text processing.
- **Pinecone**: For vector database.

  

## ‚öôÔ∏è Installation
### Clone the repository
```
git clone https://github.com/GouravJoshi19/Document-AI.git
```
Setup Environment Variables
Create a .env file in the root directory to store your API keys.

```
COHERE_API_KEY=<your-cohere-api-key>
PINECONE_API_KEY=<your-pinecone-api-key>
PINECONE_INDEX=<your-pinecone-index-name>
PINECONE_API_ENV=<pinecone-environment-region>
```
Install Dependencies
Create a virtual environment and install the required dependencies:

```
python3 -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
```
üê≥ Docker Setup This project includes a Docker setup for easy deployment.

Build the Docker Image
Make sure Docker is installed and running. To build the Docker image:

```
docker build -t Document-AI . 
```
Run the Docker Container
After building the image, you can run the container using:

```
docker run -it -p 8501:8501 Document-AI
```
This will start the Streamlit application inside a Docker container, and you can access it at http://localhost:8501.

üöÄ Usage

Running Locally
After installing the dependencies, run the application:

```
streamlit run streamlit_app.py
```
Open your browser and navigate to http://localhost:8501.

1. **Upload a Document**: Use the file uploader in the sidebar to upload a document in PDF, CSV, TXT, or DOCX format.
2. **Ask Questions**: After uploading, you can start asking questions related to the document content in the chat interface.
3. **Clear Chat**: If you want to reset the chat, use the "Clear Chat" button in the sidebar.

Running with Docker
If using Docker, after starting the container, access the application at http://localhost:8501.


üß© **Application Flow**

### 1. Upload Document
- Users upload documents using the sidebar.
- The document is preprocessed and divided into chunks.
- These chunks are embedded and stored in a Pinecone vector store.

### 2. Ask Questions
- Users input their questions through the chat interface.
- The question is processed and passed through the Langchain conversational model.
- The model interacts with the vector database to retrieve relevant content.

### 3. Answer Generation
- The answer is generated by Cohere‚Äôs language model.
- The response is displayed in the chat interface, simulating a conversation.

### 4. Clear Chat
- Users can reset the conversation by clicking the "Clear Chat" button in the sidebar.

### 5. Project Info Page
- A dedicated page explaining the project, technologies used, and current limitations.

‚ö†Ô∏è **Limitations**

#### Token Limits:
- **Cohere**: The free tier limits the number of tokens processed per month (100,000 tokens).
- **Pinecone**: Limited vector storage and query capacity on the free tier.

#### Document Size:
- Very large documents may take longer to process and query.

#### Accuracy:
- Answer accuracy depends on the quality of the document and the question asked.


üì∏ **Screenshots**

- **Main Chat Interface**:
  
![Screenshot 2024-10-16 101039](https://github.com/user-attachments/assets/9612dfca-16c8-4868-9e49-94d838393c1d)


- **Project Info Page**:
  
![Screenshot 2024-10-16 101109](https://github.com/user-attachments/assets/50027d95-e824-4487-8c93-e1396f845bce)

---

‚ú® **Contributing**

Feel free to open issues, request features, or contribute to the project through pull requests.

---

üîó **Links**

- **Cohere API**: [Cohere](https://cohere.ai/)
- **Pinecone**: [Pinecone](https://www.pinecone.io/)
- **Langchain**: [Langchain](https://www.langchain.com/)

